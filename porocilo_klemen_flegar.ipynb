{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64cb5888",
   "metadata": {},
   "source": [
    "<img style=\"float: center; width: 100%\" src=\"https://raw.githubusercontent.com/andrejkk/TalksImgs/master/FrontSlideUpperBan.png\">\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "\n",
    "\n",
    "# Chest X-ray Classification\n",
    "\n",
    "Ime Priimek: Klemen Flegar\n",
    "\n",
    "Predmet: Optimizacija v telekomunikacijah\n",
    "\n",
    "Datum: 10. 5. 2025\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e57ed74",
   "metadata": {},
   "source": [
    "## Kazalo\n",
    "\n",
    "\n",
    "[Povzetek](#povzetekMain)\n",
    "\n",
    "1. [Uvod](#uvod)\n",
    "    1. [Opredelitev področja](#opredelitev-podrocja)\n",
    "    2. [Predstavitev problema](#predstavitev-problema) \n",
    "2. [Teoretično ozadje in trenutno stajne](#teoreticno-ozadje)\n",
    "    1. [Teoretični vidiki problema](#teoretični-vidiki-problema)\n",
    "    2. [Algoritmi](#algoritmi)\n",
    "    3. [Merjenje uspešnosti](#merjenje-uspesnosti-resitve)\n",
    "3. [Eksperimentalni del](#eksperimentalni-del)\n",
    "    1. [Podatki](#podatki)\n",
    "    2. [Eksperimentalni rezultati 1](#eksperimentalni-rezultati-1)\n",
    "    3. [Eksperimentalni rezultati 2](#eksperimentalni-rezultati-2)\n",
    "4. [Zaključek in razprava](#zakljucek-in-razprava)\n",
    "5. [Doseženi učni izidi](#dosezeni-ucni-izidi)\n",
    "6. [Literatura in viri](#literatura-in-viri)\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b01f137",
   "metadata": {},
   "source": [
    "## Povzetek <a class=\"anchor\" id=\"povzetekMain\"></a>\n",
    "\n",
    "Cilj projekta je bila ustrezna implementacija in prilagoditev konvolucijsko nevronske mreže modela EfficientNet za klasifikacijo rentgenskih slik pljuč.\n",
    "</br>\n",
    "\n",
    "1. Izhodišča: \n",
    "    1. Klasifikacija rentgenskih slik pacientov: v sodobni medicini analiza rentgenskih pacientov ključnega pomena pri postavljanju diagnoz, vendar je časovno zahtevna. \n",
    "    2. Raziskovalni cilj: glavni cilj projekta je bil razumeti delovanje konvolucijskih nevronskih mrež, predvsem iz perspektive implementacije in učenja. Hkrati je bil cilj izdelati koncept programa z modelom, ki bi bil sposoben klasificirati rentgenske slike pljuč. \n",
    "2. Rezultati:\n",
    "    1. Razvit je bil CNN model na osnovi arhitekture vnaprej naučenega modela EfficientNet-B0. Zraven se je iskala optimalna kombinacija parametrov učenja modela ter algoritmov za doseganje maksimalne natančnosti z omejeno količino podatkov.\n",
    "    2. Kot rezultat projekta je nastal terminalski program z uporabniškim vmesnikom. Program omogoča uporabniku ustvarjanje, učenje, testiranje in brisanje različici izbranega CNN modela. Dodatno program za vsak model shrani njegov povzetek v obliki ».txt« datoteke.\n",
    "3. Prihodnje raziskovalne smeri:\n",
    "    1. Omogočiti podporo drugih CNN modelov. V trenutni izvedbi projekt omogoča uporabniku samo uporabo »EfficientNet-B0« modela z različnimi parametri.\n",
    "    2. Dodati možnosti za izbor drugih optimizacijskih algoritmov. V trenutni izvedbi projekt uporablja »Adam« algoritem.\n",
    "    3. Dodati možnosti izbora kombinacije zadnjih plasti nevronske mreže. V trenutni izvedbi ima projekt statično določeno kombinacijo zadnjih plasti nevronske mreže. Uporabniku bi se lahko dodelila možnost lastnega izbora kombinacije plasti, vendar to lahko privede do številnih drugih komplikacij.\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8a5676",
   "metadata": {},
   "source": [
    "## 1. Uvod <a class=\"anchor\" id=\"uvod\"></a>\n",
    "<p>\n",
    "Z napredkom v tehnologiji se danes umetno inteligenco uporablja na najrazličnejših področjih, kar da odlično priložnost za poskus avtomatizacije medicinske diagnoze. Rentgenske slike danes predstavljajo zelo pomembno diagnostično orodje, saj nam omogočajo pogled v notranjost človeškega telesa brez invazivnih posegov. Rentegnske slike pljuč se pogosto uporabi za diagnozo pogostih dihalnih bolezni, med katerima sodita bakterijska in virusna pljučnica. Kljub temu interpretacija slik zahteva visoko strokovno znanje, izkušnje in je pogosto časovno zahtevna.</br>\n",
    "</br>\n",
    "V zadnjem desetletju je umetna inteligenca doživela velik napredek na številnih področjih. Eden izmed področij, ki je doživel velik razvoj so konvolucijske nevronske mreže (CNN). Z razvojem računalniške opreme, interneta in algoritmov lahko danes ustvarimo CNN modele, ki so zelo učinkoviti pri razpoznavanju vzorcev in klasifikaciji slik.\n",
    "Cilj projekta je bil razviti sistem za klasifikacijo rentgenskih slik pljuč z uporabo CNN arhitekture EfficientNet. Model razvršča slike v sledeče tri kategorije:\n",
    "<ol>\n",
    "    <li>NORMAL (zdrava pljuča),</li>\n",
    "    <li>BACTERIAL (pljuča z bakterijsko pljučnico),</li>\n",
    "    <li>VIRAL (pljuča z virusno pljučnico).</li>\n",
    "</ol>   \n",
    "Uporabljeni so bili vnaprej označeni podatki in model je bil implementiran s pomočjo ogrodja PyTorch.\n",
    "</p>\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a26cc86",
   "metadata": {},
   "source": [
    "### 1.1. Opredelitev področja <a class=\"anchor\" id=\"opredelitev-podrocja\"></a>\n",
    "<p>\n",
    "V zadnjem času se zdravstveni sistemi po vsem svetu soočajo z vedno večjo količino podatkov, še posebej na področju medicinskega slikanja, kot so rentgenske slike. Te slike je treba natančno pregledati in pravilno interpretirati, kar zahteva veliko znanja in izkušenj ter časa, ki ga v zdravstvu pogosto primanjkuje. Posledično se pojavljajo daljše čakalne dobe, večje obremenitve za zdravnike in večja verjetnost, da pride do napak.</br></br>\n",
    "Ravno tukaj lahko umetna inteligenca ponudi pomoč. Sodobne metode, kot so konvolucijske nevronske mreže (CNN), znajo zelo dobro prepoznavati vzorce na slikah tudi takšne, ki jih človeško oko težko opazi. Namen takšnih orodij ni, da bi zamenjala zdravnika, ampak da mu stojijo ob strani kot dodatna pomoč. Tako lahko zdravniki hitreje pridejo do diagnoze in se bolj posvetijo bolnikom.\n",
    "</p>\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112e5e31",
   "metadata": {},
   "source": [
    "### 1.2. Predstavitev problema <a class=\"anchor\" id=\"predstavitev-problema\"></a>\n",
    "<p>\n",
    "Glavni cilj projekta je bil razviti model strojnega učenja, ki je sposoben klasificirati rentgenske slike pljuč v enega izmed teh možnih razredov in sicer: zdrava pljuča (NORMAL), pljuča z bakterijsko pljučnico (BACTERIAL) in pljuča z virusno pljučnico (VIRAL).</br></br>\n",
    "V tem primeru gre za nadzorovano učenje (supervised learning) kjer se izvaja večrazredna klasifikacija slik (multi-class classification). Množica vhodnih slik je razdeljena v 3 podmnožice in sicer: učna množica (train), testna množica (test) in validacijska množica (val). Znotraj posamezne množice so vse slike označene z pripadajočo oznako, kar nam da nadzorovani pristop učenja modela.</br></br>\n",
    "Z reševanje problema je bila izbrana konvolucijska nevronska mreža EfficientNet-B0, ki omogoča učenje prepoznavanja kompleksnih vzorcev. Model EfficientNet-B0 je vnaprej naučen in s pomočjo pristopa »fine-tunning« je bil prilagojen na izbrano množico vhodnih podatkov.\n",
    "</p>\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0384e4",
   "metadata": {},
   "source": [
    "## 2. Teoretično ozadje in trenutno stanje <a class=\"anchor\" id=\"teoreticno-ozadje-in-trenutno-stanje\"></a>\n",
    "\n",
    "V sledečem poglavju so predstavljeni temeljni koncepti uporabljeni za reševanje problema klasifikacije medicinskih slik s pomočjo konvolucijskih nevronskih mrež. \n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478e9ccf",
   "metadata": {},
   "source": [
    "### 2.1. Teoretični vidiki problema <a class=\"anchor\" id=\"teoretični-vidiki-problema\"></a>\n",
    "\n",
    "<p>\n",
    "V sledečem poglavju so predstavljeni temeljni koncepti uporabljeni za reševanje problema klasifikacije medicinskih slik s pomočjo konvolucijskih nevronskih mrež. \n",
    "\n",
    "Konvolucijske nevronske mreže (CNN – Convolutional Neural Network) nam predstavljajo podvrsto »feedforward« nevronskih mrež, ki temeljijo na učenju prepoznavanja lastnosti na podlagi optimizacije filtra oz. jedra (kernel).\n",
    "\n",
    "Konvolucijske nevronske mreže (CNN) so dobile svoje ime po matematični operaciji konvolucija, ki jo izvajajo na posamezni plasti med obdelavo podatkov. Osnovna ideja (v kontekstu slike) temelji na temu, da se majhni filtri (oz. jedra) premikajo čez vhodno sliko in izvajajo filtriranje. Vhodno sliko se predstavi kot tri dimenzionalen tenzor (širina x višina x barvni kanal) in filtriranje se v prostoru slike predstavi z operacijo konvolucije. Vsaka konvolucijska plast nevronske mreže ima več filtrov s svojimi parametri, ki se spreminjajo med procesom učenja. Kot rezultat filtriranja filtri vrnejo »feature map«, ki predstavlja odziv filtra na posamezne dele slike. Izhod ene plasti je v obliki »feature maps«, ki postane vhod naslednji plasti, kar omogoča zaznavo vedno bolj kompleksnih vzorcev, struktur,… S tem pristopom konvolucijske nevronske mreže postopoma gradijo hierarhično predstavitev podatkov, ki začne z osnovnimi značilnostmi in konča pri kompleksnejših vzorcih slike.\n",
    "\n",
    "Konvolucijske nevronske mreže običajno vsebujejo sledeče komponente:\n",
    "<ol>\n",
    "<li>Konvolucijske plasti – so plasti, ki na podlagi operacije konvolucije postopoma izluščijo posamezne lastnosti slike kot so: teksture, robovi, kompleksnejši vzorci,…Pri iskanju lastnosti se izkorišča medsebojna povezanost sosednjih slikovnih točk (pixel) ter lastnosti se izluščijo v obliki »feature map«.</li>\n",
    "<li>»Pooling« plasti – so plasti, ki postopoma znižujejo dimenzije vhodnih podatkov (downsample) z namen znižanja računske zahtevnosti in zmanjševanja števila parametrov.</li>\n",
    "<li>Aktivacijska funkcija – je funkcija, ki se pogosto uporablja v nevronskih mrežah z namen implementacije nelinearnosti. Dodana nelinearnost omogoča nevronskim mrežam učenje kompleksnejših relacij med vhodnimi podatki.</li>\n",
    "<li>Polno povezane (fully connected) plasti – so plasti, ki so odgovorne za izvajanje klasifikacije na podlagi izluščenih lastnosti.</li>\n",
    "\n",
    "</ol>\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c6794a",
   "metadata": {},
   "source": [
    "### 2.2. Algoritmi <a class=\"anchor\" id=\"algoritmi\"></a>\n",
    "\n",
    "#### EfficientNet-B0\n",
    "\n",
    "Za reševanje izbranega problema se je uporabil vnaprej treniran model EfficientNetB0, ki je bil predstavljen v članku Tan, M., & Le, Q. V. (2019). EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. Delovanje EffiecientNet-B0 temelji na **compound scaling**, ki sočasno spreminja širino (oz. število kanalov) , globino (oz. število plasti) in ločljivost omrežja. Sledeči pristop omogoča boljšo učinkovitost omrežja glede na razmerje med natančnostjo in porabo virov. Primer različnega prilagajanja omrežja lahko vidimo na spodnji sliki:\n",
    "\n",
    "<img src=\"other/compound_scaling.png\" alt=\"Primer prilagajanja omrežja\" width=\"600\" height=\"300\">\n",
    "\n",
    "\n",
    "- Skaliranje globine (depth scaling): s skaliranjem globine omrežja (oz. večanjem števila plasti) omogočimo omrežju učenje kompleksnejših vzorcev z večjo porabo računalniških virov.\n",
    "- Skaliranje širine (width scaling): s skaliranjem širine omrežja (oz. večanjem števila kanalov v vsaki plasti) povečamo kapaciteto omrežja, kar posledično omogoča omrežju zajem večjega števila raznolikih lastnosti vhodnih podatkov.\n",
    "- Skaliranje ločljivosti (resolution scaling): s skaliranjem ločljivosti vhodne slike omogočimo, omrežju zajem podrobnejših detajlov slike, kar privede do večje natančnosti omrežja pri razločevanju različnih razredov, vendar večja vhodna ločljivost slike zahteva več računalniških virov.\n",
    "\n",
    "\n",
    "Pri reševanju problema je uporaba vnaprej treniranega modela EfficientNet-B0 predstavljala veliko prednost, saj ni potrebno ustvarjati modela od čistega začetka. Torej lahko uporabimo model, ki je že dovolj naučen za dobro prepoznavanje robov, tekstur in obliki ter ga prilagodimo na naše podatke. Takemu pristopu pravimo »fine tuning«.\n",
    "»Fine-tuning« je tehnika, kjer uporabimo model prehodno naučen na veliki zbirki podatkov kot npr. ImageNet in ga delno prilagodimo za specifično nalogo oz. podatke. Proces »fine-tuning« pogosto zajema sledeče tri ključne korake:\n",
    "\n",
    "- Zamrznitev zgornjih plasti z namenom ohranjevanje njihovih lastnosti (med učenjem se te plasti ne bodo spreminjale).\n",
    "- Prilagoditev zadnjih plasti ali dodajanje novih plasti, ki se učijo specifične značilnosti naših podatkov.\n",
    "- Treniranje novo prilagojenih ali dodanih plasti na naših podatkih, kjer se pogosto uporabi manjša hitrost učenja (learning rate) z namenom izogibanja prekomernemu prilagajanju (overfitting).\n",
    "\n",
    "Primer implementacije modela EfficientNet-B0 in uporaba pristopa »fine-tuning« lahko vidimo v datoteki [model.py](model.py#L11) (v razdelku `Create EfficientNet model`).\n",
    "\n",
    "Najprej se z ukazom `self.model = models.efficientnet_b0()` naloži vnaprej naučen model. Zatem v naslednjih dveh vrsticah sledi zamrznitev prvih 5 plasti v \"features\" delu modela:\n",
    "\n",
    "```python\n",
    "for param in list(self.model.features.parameters())[:5]:\n",
    "    param.requires_grad = False\n",
    "```\n",
    "\n",
    "\n",
    "Zamrznitev prvih 5 slojev se naredi z namenom ohranitve splošno koristnih značilnosti modela naučene iz ImageNet podatkovne zbirke. Ti sloji ostanejo nespremenjeni med učenjem modela.\n",
    "</br>Zatem Po zamrznitvi zamrznitvi začetnih slojev modela sledi prilagoditev klasifikatorja za reševanje podane naloge:\n",
    "\n",
    "```python\n",
    "        features = self.model.classifier[1].in_features\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            # -----------------------------------\n",
    "            # Original layer setup\n",
    "            # nn.Linear(features, 128),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            # nn.Linear(128, classNum),\n",
    "            # ------------------------------------\n",
    "            # potential layer setup\n",
    "            # nn.Linear(features, 512),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(512, 128),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            # nn.Linear(128, classNum),\n",
    "            # ---------------------------------\n",
    "            # Final layer setup\n",
    "            nn.Linear(features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.4), \n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, classNum),\n",
    "        )\n",
    "```\n",
    "Najprej se v spremenljivko `features` shrani število vhodnih enot zadnjega sloja (oz. shrani se velikost izhoda zadnjega sloja) pred trenirane mreže. Nato se klasifikator nadomesti z novo strukturo zaporednih plasti, ki bodo trenirane na specifičnih podatkih dane naloge. Dodane plasti so sledeče:\n",
    "\n",
    "- `nn.Linear()` - plast ki naredi linearno afino transformacijo nad vhodnimi podatki.\n",
    "- `nn.ReLU()` - aktivacijska funkcija ki doda nelinearnost model.\n",
    "- `nn.BatchNorm1d()` - normalizira vrednosti ter pomaga pripomore k stabilnejšemu učenju.\n",
    "- `nn.Dropout()` - naključno izklaplja nevrone med učenjem z namenom zmanjševanja možnosti prenaučenosti (*overfitting*).\n",
    "\n",
    "#### Adam Optimizer\n",
    "\n",
    "Pri učenju nevronske mreže modela EfficientNet-B0 je bil uporabljen optimizacijski algoritem **Adam optimizer** (oz. *Adaptive Moment Estimation*). Uporabo algoritma v projektu lahko vidimo v [trainEval.py](trainEval.py#L211) (vrtsica 211). Adam združuje prednosti dveh uveljavljenih tehnik **Momentum** in **RMSprop**. Gre za široko uporabljen algoritem pri globokem učenju, saj omogoča hitro in stabilno konvergenco kompleksnih modelov.\n",
    "\n",
    "**Adam optimizer** ohranja dve eksponentni povprečji in sicer:\n",
    "- Prvi moment – povprečje gradienta (podobno kot pri Momentum).\n",
    "- Drugi moment – povprečje kvadrata gradienta (podobno kot pri RMSprop).\n",
    "\n",
    "Povprečja se uporabljajo za prilagajanje velikosti koraka (oz. *learning rate*) pri posodabljanju parametrov modela.\n",
    "\n",
    "\n",
    "##### Momentum\n",
    "\n",
    "Se uporablja za pospešitev gradientnega spusta z uporabo eksponentnega povprečja gradientov. Posodabljanje uteži z Momentum je podano z naslednjo formulacijo:\n",
    "$$\n",
    "w_{t+1}=w_{t}-\\alpha m_{t}\n",
    "$$\n",
    "Pri čemer:\n",
    "-  $m_{t}$ - predstavlja povprečje gradientov v trenutku *t*,\n",
    "-  $\\alpha$ - predstavlja hitrost učenja (oz. *learning rate*),\n",
    "-  $w_{t}$, $w_{t+1}$ - predstavljata vrednosti uteži v trenutku $t$ in $t+1$.\n",
    "\n",
    "Parameter momentuma $m_{t}$ se rekurzivno posodablja po naslednji formulaciji:\n",
    "$$\n",
    "m_{t}=\\beta_{1}m_{t-1}+(1-\\beta_{1})\\frac{\\partial L}{\\partial w_{t}}\n",
    "$$\n",
    "Pri čemer:\n",
    "- $\\beta_{1}$ - predstavlja parameter momentuma,\n",
    "- $\\frac{\\partial L}{\\partial w_{t}}$ - predstavlja parcialni odvod *loss funkcije* (oz. kriterijske funkcije) $L$ po vseh utežeh $w_{t}$.\n",
    "\n",
    "##### RMSprop\n",
    "\n",
    "Je metoda za adaptivno prilagajanje hitrost učenja na podlagi računanja eksponentnega povprečja kvadrata gradienta. Metoda preprečuje hitrosti učenja, ki postane premajhna v postopku optimizacije. RMSprop je podan z naslednjo formulacijo:\n",
    "$$\n",
    "w_{t+1}=w_{t}-\\frac{\\alpha_{t}}{\\sqrt{v_{t}+\\epsilon}}\\frac{\\partial L}{\\partial w_{t}}\n",
    "$$\n",
    "Pri čemer:\n",
    "- $v_{t}$ - predstavlja eksponentno povprečje gradientov:\n",
    "$$\n",
    "v_{t} = \\beta_{2} v_{t-1} + (1 - \\beta_{2}) \\left( \\frac{\\partial L}{\\partial w_{t}} \\right)^{2}\n",
    "$$\n",
    "- $\\epsilon$ - je majhna dodana konstanta ($\\sim 10^{-8}$) za preprečevanje deljenja z $0$,\n",
    "- $\\alpha_{k}$ - je prilagojena hitrost učenja. \n",
    "\n",
    "Tako Adam optimizer združi funkcionalnosti Momentum in RMSprop, da zagotovi uravnotežen in učinkovit optimizacijski postopek. Glavne enačbe, ki predstavljajo Adam optimizer so:\n",
    "- Prvi moment (*Momentum*):\n",
    "$$\n",
    "m_{t}=\\beta_{1}m_{t-1}+(1-\\beta_{1})\\frac{\\partial L}{\\partial w_{t}}\n",
    "$$\n",
    "- Drugi moment (*RMSprop*):\n",
    "$$\n",
    "v_{t} = \\beta_{2} v_{t-1} + (1 - \\beta_{2}) \\left( \\frac{\\partial L}{\\partial w_{t}} \\right)^{2}\n",
    "$$\n",
    "- Bias korekcija - je potrebna, zato ker $m_{t}$ in $v_{t}$ sta inicializirana pri vrednosti 0 in izražata pristranskost proti 0, še posebej v začetnih korakih algoritma:\n",
    "$$\n",
    "\\hat{m_{t}}=\\frac{m_{t}}{1-\\beta_{1}^{t}},\\quad\\quad\\hat{v_{t}}=\\frac{v_{t}}{1-\\beta_{2}^{t}}\n",
    "$$\n",
    "- Končno posodobitev uteži $w_{t}$ se naredi po naslednji enačbi:\n",
    "$$\n",
    "w_{t+1}=w_{t}-\\frac{\\hat{m_{t}}}{\\sqrt{\\hat{v_{t}}}+\\epsilon}\\alpha\n",
    "$$\n",
    "Glavne konstante Adam optimizer so:\n",
    "- $\\alpha$ - predstavlja hitrost učenja (oz. *learning rate*), katere vrednost znaša $0.001$.\n",
    "- $\\beta_{1}$, $\\beta_{2}$ - predstavljata konstanti hitrosti upadanja povprečja gradientov. Njuna vrednost se nahaja okoli $0.9$.\n",
    "- $\\epsilon$ - predstavlja majhno pozitivno konstanto ($\\sim 10^{-8}$), da se izognemo deljenju z $0$.\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8822f3a3",
   "metadata": {},
   "source": [
    "### 2.3. Merjenje uspešnosti rešitve <a class=\"anchor\" id=\"merjenje-uspesnosti-resitve\"></a>\n",
    "\n",
    "Pri projektu je v kodi [trainEval.py](trainEval.py#L317) podan razdelek `#model summary`, kjer se z uporabo funkcij kot so `confusion_matrix()` in `classification_report()` meri uspešnost modela. Dodatno se celotna izmerjena uspešnost shrani v obliki .txt datoteke z namenom hranjenja in kasnejše analize. Primer takšne datoteke: [ModelV1_report.txt](models\\reports\\ModelV1_report.txt).\n",
    "Pri določanju uspošnosti naučenega modela se uporablja več različnih metrik kot so:\n",
    "- Accuracy,\n",
    "- Precision,\n",
    "- Recall,\n",
    "- F1-score,\n",
    "- Support,\n",
    "- Confusion Matrix. \n",
    "\n",
    "\n",
    "</br>\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca58cb",
   "metadata": {},
   "source": [
    "## 3. Eksperimentalni del <a class=\"anchor\" id=\"eksperimentalni-del\"></a>\n",
    "\n",
    "\n",
    "Opis eksperimenta na način, ki bi bralcu omogočal njegovo ponovitev - če bi razpolagal s podatki in ustreznim znanjem.\n",
    "\n",
    "Eksperimentalne rezultate navajamo po smiselnih skupinah, spodaj je navedeno za primer dveh skupin.\n",
    "\n",
    "Projekt opremite z navodili za zagon programske kode vključno z dostopom do testnih podatkov (ali pripnete ali podate povezavo). Ta navodila vključujejo tudi potrebne knjižnice in druge nastavitve, potrebne za zagon kode. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d84bb96",
   "metadata": {},
   "source": [
    "### 3.1. Podatki <a class=\"anchor\" id=\"podatki\"></a>\n",
    "\n",
    "\n",
    "Predstavimo testne podatke (izvor, velikost, podatkovna polja, lastnosti). Za javno dostopne podatke navedemo povezavo do skladišča. \n",
    "Dobrodošla je slika primerov podatkov če gre za časovno odvisne podatke ipd. \n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e120716c",
   "metadata": {},
   "source": [
    "### 3.2. Eksperimentalni rezultati 1 <a class=\"anchor\" id=\"eksperimentalni-rezultati-1\"></a>\n",
    "\n",
    "\n",
    "Predstavitev eksperimentalnih rezultatov, tabele, grafi, kratka interpretacija. \n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74cc2ad",
   "metadata": {},
   "source": [
    "## 4. Zaključek in razprava <a class=\"anchor\" id=\"zakljucek-in-razprava\"></a>\n",
    "\n",
    "\n",
    "Zaključki - kaj lahko sklepamo neposredno iz eksperimentalnih rezultatov v strogem smislu, to je kar sledi neposredno iz dobljenih rezultatov. \n",
    "\n",
    "\n",
    "Glavni rezultati - povzetek v smislu glavne ugotovitve. Kaj sledi iz doseženih rezultatov. \n",
    "\n",
    "\n",
    "Opažanja in razprava - tu so na mestu širša opazanja, lahko tudi sama mnenja glede doseženih rezultatov. \n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc63b80c",
   "metadata": {},
   "source": [
    "## 5. Doseženi učni izidi <a class=\"anchor\" id=\"dosezeni-ucni-izidi\"></a>\n",
    "\n",
    "\n",
    "Kaj ste se pri izdelavi projekta naučili. Na kratko v poljudnem jeziku, med drugim:\n",
    "- Razumevanje teoretičnih konceptov.\n",
    "- Spoznavanje algoritmov. \n",
    "- Pridobljene izkušnje s podatki.\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b95fe2f",
   "metadata": {},
   "source": [
    "## 6. Literatura in viri  <a class=\"anchor\" id=\"literatura-in-viri\"></a>\n",
    "\n",
    "Seznam literature \n",
    "\n",
    "Explores the VAD (Valence, Arousal, Dominance) model and its application in understanding human emotions.\n",
    "Wickens, C. D. (2008). \"Multiple Resources and Mental Workload.\" Human Factors: The Journal of the Human Factors and Ergonomics Society.\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"margin-bottom:2cm;\"></p>\n",
    "<img src=\"https://raw.githubusercontent.com/andrejkk/ORvTK_SlidesImgs/master/footer_full.jpg\">"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
